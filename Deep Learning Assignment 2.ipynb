{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8UcgZTDNgz9E",
        "yAZrdpfeONGJ",
        "ymVprLKSe781",
        "_HjuGoShOT-F",
        "shgRBn9a0P5b"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UcgZTDNgz9E"
      },
      "source": [
        "#Download Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJZsbdKP6f4I",
        "outputId": "72289954-3a1f-46f4-fee0-c2f744eb1ac7"
      },
      "source": [
        "# Download data\n",
        "\n",
        "!gdown --id 1p1wjaqpTh_5RHfJu4vUh8JJCdKwYMHCp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p1wjaqpTh_5RHfJu4vUh8JJCdKwYMHCp\n",
            "To: /content/lfwa.zip\n",
            "104MB [00:00, 136MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZM14C-8MtC"
      },
      "source": [
        "# Unzip data\n",
        "\n",
        "!unzip lfwa.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WsarS-w-YqZ",
        "outputId": "3caf764c-40c3-4cbc-97ef-7440cc395e10"
      },
      "source": [
        "# Download train and test\n",
        "\n",
        "!gdown http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt\n",
        "!gdown http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt\n",
            "To: /content/pairsDevTest.txt\n",
            "100% 26.0k/26.0k [00:00<00:00, 824kB/s]\n",
            "Downloading...\n",
            "From: http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt\n",
            "To: /content/pairsDevTrain.txt\n",
            "100% 56.6k/56.6k [00:00<00:00, 894kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by3fyulXg5L1"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVxixQTl-phE",
        "outputId": "eb21343d-1ef3-4096-8d83-a19504df4f4a"
      },
      "source": [
        "# People amount\n",
        "import os\n",
        "\n",
        "data_path = \"data/lfw2/lfw2\"\n",
        "people_list = os.listdir(data_path)\n",
        "people_count = len(people_list)\n",
        "print(f\"There are {people_count} people's images in the dataset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 5749 people's images in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzo_-rIphDYb"
      },
      "source": [
        "train_file_path = \"pairsDevTrain.txt\"\n",
        "test_file_path = \"pairsDevTest.txt\"\n",
        "data_path = \"data/lfw2/lfw2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk0WSSNJfZv1"
      },
      "source": [
        "# create data list\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def load_txt_file_data(txt_file_path, create_validation=False):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "  data = open(txt_file_path).read()\n",
        "  data_list = data.split('\\n')\n",
        "  last_same_pairs_ind = int(data_list[0]) + 1\n",
        "  \n",
        "\n",
        "  same_pairs_list = data_list[1:last_same_pairs_ind]\n",
        "  different_pairs_list = data_list[last_same_pairs_ind:]\n",
        "\n",
        "  # create a list of tuples with (1st person name, 1st person pic number,\n",
        "  # 2nd person name, 2nd person pic number, label) when label is 0 for different\n",
        "  # and 1 for same\n",
        "  same_list = []\n",
        "  different_list = []\n",
        "  \n",
        "\n",
        "  # process same pairs\n",
        "  for pair in same_pairs_list:\n",
        "    pair_data = pair.split('\\t')\n",
        "    name = pair_data[0]\n",
        "    first_img = pair_data[1]\n",
        "    second_img = pair_data[2]\n",
        "    label = 1\n",
        "    pair_tuple = (name, first_img, name, second_img, 1)\n",
        "    same_list.append(pair_tuple)\n",
        "\n",
        "  # process different pairs\n",
        "  for pair in different_pairs_list:\n",
        "    if pair == \"\":\n",
        "      continue\n",
        "    pair_data = pair.split('\\t')\n",
        "    first_name = pair_data[0]\n",
        "    first_img = pair_data[1]\n",
        "    second_name = pair_data[2]\n",
        "    second_img = pair_data[3]\n",
        "    label = 0\n",
        "    pair_tuple = (first_name, first_img, second_name, second_img, 0)\n",
        "    different_list.append(pair_tuple)\n",
        "\n",
        "  if create_validation:\n",
        "    # get 10% of the data equally from same and different pairs for the validation\n",
        "    # set\n",
        "    val_ratio = 0.1\n",
        "    val_per_list_size = int(0.1 * len(same_list))\n",
        "\n",
        "    val_list = same_list[:val_per_list_size] + different_list[:val_per_list_size]\n",
        "\n",
        "    data_list = same_list[val_per_list_size:] + different_list[val_per_list_size:]\n",
        "\n",
        "    # shuffle the lists\n",
        "    random.shuffle(data_list)\n",
        "    random.shuffle(val_list)\n",
        "\n",
        "    return data_list, val_list\n",
        "  \n",
        "  # if not creating validation set\n",
        "  data_list = same_list + different_list\n",
        "  random.shuffle(data_list)\n",
        "  return data_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNWrR9QMogTV"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_image_path(name, pic_num, data_path = data_path):\n",
        "  dir_path = os.path.join(data_path, name)\n",
        "  dir_files = os.listdir(dir_path)\n",
        "\n",
        "  for file_name in dir_files:\n",
        "    if file_name.endswith(f\"{pic_num}.jpg\"):\n",
        "      file_path = os.path.join(os.path.join(data_path, name), file_name)\n",
        "      return file_path\n",
        "  \n",
        "\n",
        "def get_pairs_pics_label(data_list):\n",
        "  \"\"\"\n",
        "  gets a data list of tuples and returns two pictures in gray scale and\n",
        "  their label - 0 for different and 1 for same\n",
        "  \"\"\"\n",
        "  \n",
        "  res_list = []\n",
        "\n",
        "  for pair in data_list:\n",
        "    first_name, first_pic_num, second_name, second_pic_num, label = pair\n",
        "    \n",
        "    first_img_path = get_image_path(first_name, first_pic_num)\n",
        "    second_img_path = get_image_path(second_name, second_pic_num)\n",
        "\n",
        "    # img_size=(105,105)\n",
        "    first_img = load_img(path = first_img_path, color_mode = 'grayscale')\n",
        "    first_img = img_to_array(first_img)\n",
        "    first_img = tf.image.central_crop(first_img, 0.5)\n",
        "    # first_img = first_img / 255.0\n",
        "    second_img = load_img(path = second_img_path, color_mode = 'grayscale')\n",
        "    second_img = img_to_array(second_img)\n",
        "    second_img = tf.image.central_crop(second_img, 0.5)\n",
        "    # second_img = second_img / 255.0\n",
        "\n",
        "    pair_data = (first_img, second_img, label)\n",
        "    res_list.append(pair_data)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  return res_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il0ZH6Iun71Y"
      },
      "source": [
        "def get_x_y(data):\n",
        "  \"\"\"\n",
        "  gets a data list of tuples (image, image, label) and returns an np.array\n",
        "  of [left_input, right input] and an np.array of y labels\n",
        "  \"\"\"\n",
        "\n",
        "  X1_list = []\n",
        "  X2_list = []\n",
        "  y_list = []\n",
        "  for sample in data:\n",
        "    first_img, second_img, label = sample\n",
        "    X1_list.append(first_img)\n",
        "    X2_list.append(second_img)\n",
        "    y_list.append(label)\n",
        "  \n",
        "  return X1_list, X2_list, y_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSRuLkcoNHFK"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEtNshAGp_F"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Lambda, Input, Flatten, Dense, Concatenate, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from scipy.spatial.distance import cosine\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def l1_dist(vect):\n",
        "    x, y = vect\n",
        "    return abs(x-y)\n",
        "\n",
        "def l2_dist(vect):\n",
        "    x, y = vect\n",
        "    return (x-y)*(x-y)\n",
        "\n",
        "\n",
        "def get_model(with_batch_normalization=False, distance_func = 'l1', input_shape= (105,105,1)):\n",
        "  W_init_1 = RandomNormal(mean=0, stddev=0.01)\n",
        "  b_init = RandomNormal(mean=0.5, stddev = 0.01)\n",
        "  W_init_2 = RandomNormal(mean=0, stddev=0.2)\n",
        "\n",
        "  # input_shape = (105, 105, 1)\n",
        "  left_input = Input(input_shape)\n",
        "  right_input = Input(input_shape)\n",
        "\n",
        "  convnet = Sequential()\n",
        "  # convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape, kernel_initializer=W_init_1, bias_initializer = b_init ,kernel_regularizer=l2(2e-4)))\n",
        "  convnet.add(Conv2D(64,(10,10),activation='relu'))\n",
        "  if with_batch_normalization:\n",
        "    convnet.add(BatchNormalization())\n",
        "  convnet.add(MaxPooling2D())\n",
        "  # convnet.add(Dropout(0.5))\n",
        "  # convnet.add(Conv2D(128,(7,7),activation='relu', kernel_initializer=W_init_1, bias_initializer = b_init ,kernel_regularizer=l2(0.05)))\n",
        "  convnet.add(Conv2D(128,(7,7),activation='relu'))\n",
        "  if with_batch_normalization:\n",
        "    convnet.add(BatchNormalization())\n",
        "  convnet.add(MaxPooling2D())\n",
        "  # convnet.add(Dropout(0.5))\n",
        "  # convnet.add(Conv2D(128,(4,4),activation='relu', kernel_initializer=W_init_1, bias_initializer = b_init ,kernel_regularizer=l2(0.05)))\n",
        "  convnet.add(Conv2D(128,(4,4),activation='relu'))\n",
        "  if with_batch_normalization:\n",
        "    convnet.add(BatchNormalization())\n",
        "  convnet.add(MaxPooling2D())\n",
        "  # convnet.add(Dropout(0.5))\n",
        "  # convnet.add(Conv2D(256,(4,4),activation='relu', kernel_initializer=W_init_1, bias_initializer = b_init ,kernel_regularizer=l2(0.05)))\n",
        "  convnet.add(Conv2D(256,(4,4),activation='relu'))\n",
        "  if with_batch_normalization:\n",
        "    convnet.add(BatchNormalization())\n",
        "  convnet.add(Flatten())\n",
        "  # convnet.add(Dense(4096,activation=\"sigmoid\", kernel_initializer=W_init_2, bias_initializer = b_init ,kernel_regularizer=l2(0.05)))\n",
        "  convnet.add(Dense(4096,activation=\"sigmoid\"))\n",
        "  encoded_l = convnet(left_input)\n",
        "  encoded_r = convnet(right_input)\n",
        "\n",
        "  if distance_func=='l1':\n",
        "    merge_layer = Lambda(l1_dist)([encoded_l,encoded_r])\n",
        "  elif distance_func=='l2':\n",
        "    merge_layer = Lambda(l2_dist)([encoded_l,encoded_r])\n",
        "\n",
        "  prediction = Dense(1,activation='sigmoid')(merge_layer)\n",
        "  model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "\n",
        "  \n",
        "  # model.compile(loss = 'binary_crossentropy', optimizer = SGD(lr = 0.0001, momentum = 0.5), metrics = ['accuracy'])\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.0001), metrics = ['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5WMnNiWPFXW"
      },
      "source": [
        "#Model L1 Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "300PGNB5OGcS"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pEr_jtpPEyH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_meta_data, val_meta_data = load_txt_file_data(train_file_path, create_validation = True)\n",
        "\n",
        "# process train data\n",
        "train_data = get_pairs_pics_label(train_meta_data)\n",
        "\n",
        "X1_train, X2_train, y_train = get_x_y(train_data)\n",
        "\n",
        "# add to the train set flipped one picture\n",
        "X1_train_flip, X2_train_flip, y_train_flip = get_x_y(train_data)\n",
        "for i in range(len(X1_train_flip)):\n",
        "  X1_train_flip[i] = tf.image.flip_left_right(X1_train_flip[i])\n",
        "\n",
        "# add to the train set flipped one picture\n",
        "X1_train_flip_up, X2_train_flip_up, y_train_flip_up = get_x_y(train_data)\n",
        "for i in range(len(X1_train_flip)):\n",
        "  # X1_train_flip_up[i] = tf.image.flip_up_down(X1_train_flip_up[i])\n",
        "  # X2_train_flip_up[i] = tf.image.flip_up_down(X2_train_flip_up[i])\n",
        "  X2_train_flip_up[i] = tf.image.flip_left_right(X2_train_flip_up[i])\n",
        "\n",
        "  \n",
        "\n",
        "# # add to the train set samples with random brithness change\n",
        "# X1_train_brightness, X2_train_brightness, y_train_brightness = get_x_y(train_data)\n",
        "# for i in range(len(X1_train_brightness)):\n",
        "#   X1_train_brightness[i] = X1_train_brightness[i] * 10000\n",
        "\n",
        "# create the train set\n",
        "X_train = [np.asarray(X1_train + X1_train_flip + X1_train_flip_up), np.asarray(X2_train + X2_train_flip + X2_train_flip_up)]\n",
        "# X_train = [np.asarray(X1_train + X1_train_flip), np.asarray(X2_train + X2_train_flip)]\n",
        "y_train = y_train + y_train_flip + y_train_flip_up\n",
        "# y_train = y_train + y_train_flip\n",
        "\n",
        "# process validation data\n",
        "val_data = get_pairs_pics_label(val_meta_data)\n",
        "X1_val, X2_val, y_val = get_x_y(val_data)\n",
        "X_val = [np.asarray(X1_val), np.asarray(X2_val)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlSuYXhSOI4u"
      },
      "source": [
        "## Get Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCGxwTq3QKYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e14d525-e8ee-4d1a-dfcb-45d5c45a99d7"
      },
      "source": [
        "model_l1_dist = get_model(with_batch_normalization = True, distance_func='l1', input_shape = X_train[0][0].shape)\n",
        "model_l1_dist.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           [(None, 126, 126, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           [(None, 126, 126, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_15 (Sequential)      (None, 4096)         68310080    input_31[0][0]                   \n",
            "                                                                 input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 4096)         0           sequential_15[0][0]              \n",
            "                                                                 sequential_15[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 1)            4097        lambda_15[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 68,314,177\n",
            "Trainable params: 68,313,025\n",
            "Non-trainable params: 1,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DHwejwqu7BV"
      },
      "source": [
        "## Model Training with l1 distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsVSs_NWQh90",
        "outputId": "b559fad0-a874-4a89-9652-a23b78bf1ca7"
      },
      "source": [
        "# run fit with gpu\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# add early stopping callback\n",
        "earlistopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history = model_l1_dist.fit(x= X_train, y= np.asarray(y_train).astype(np.float32), batch_size=16, epochs= 200, validation_data = (X_val, np.asarray(y_val)),\n",
        "                      callbacks=[earlistopping_callback] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "372/372 [==============================] - 29s 74ms/step - loss: 0.5973 - accuracy: 0.6614 - val_loss: 0.5005 - val_accuracy: 0.7636\n",
            "Epoch 2/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.1505 - accuracy: 0.9617 - val_loss: 0.5099 - val_accuracy: 0.7545\n",
            "Epoch 3/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0240 - accuracy: 0.9980 - val_loss: 0.4477 - val_accuracy: 0.7955\n",
            "Epoch 4/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.8136\n",
            "Epoch 5/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8182\n",
            "Epoch 6/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8091\n",
            "Epoch 7/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.8091\n",
            "Epoch 8/200\n",
            "372/372 [==============================] - 27s 73ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.8182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhBzAML9I8Ri"
      },
      "source": [
        "##Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mhp98eyJHmz"
      },
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn-RvKyGJNxO"
      },
      "source": [
        "# Test data\n",
        "test_meta_data = load_txt_file_data(test_file_path)\n",
        "test_data = get_pairs_pics_label(test_meta_data)\n",
        "X1_test, X2_test, y_test = get_x_y(test_data)\n",
        "X_test = [np.asarray(X1_test), np.asarray(X2_test)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2iUADwaJPd9"
      },
      "source": [
        "###Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnlLz_bJJTZA"
      },
      "source": [
        "# Test accuracy\n",
        "with tf.device('/device:GPU:0'):\n",
        "  pred = model_l1_dist.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA3TJ5_FJYor"
      },
      "source": [
        "###Plot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Crb2FbTVJddk",
        "outputId": "1c8278b6-1d9b-4a44-9502-c079eb6f245a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#  Train and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Train and validation loss \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77efAgstLUKU"
      },
      "source": [
        "###Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgyEW83CLW6z",
        "outputId": "44d2b569-8afd-404b-d94e-4709a4b90d9e"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77       500\n",
            "           1       0.76      0.79      0.78       500\n",
            "\n",
            "    accuracy                           0.77      1000\n",
            "   macro avg       0.77      0.77      0.77      1000\n",
            "weighted avg       0.77      0.77      0.77      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAZrdpfeONGJ"
      },
      "source": [
        "# Model L2 Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px2RWIsevAkx"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWiYzOnPHYNR"
      },
      "source": [
        "train_meta_data, val_meta_data = load_txt_file_data(train_file_path, create_validation = True)\n",
        "\n",
        "# process train data\n",
        "train_data = get_pairs_pics_label(train_meta_data)\n",
        "X1_train, X2_train, y_train = get_x_y(train_data)\n",
        "X_train = [np.asarray(X1_train), np.asarray(X2_train)]\n",
        "\n",
        "# process validation data\n",
        "val_data = get_pairs_pics_label(val_meta_data)\n",
        "X1_val, X2_val, y_val = get_x_y(val_data)\n",
        "X_val = [np.asarray(X1_val), np.asarray(X2_val)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQZuw1LEHkZZ"
      },
      "source": [
        "##Get Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl3It51wHxDI",
        "outputId": "66792d1d-9ae2-46dd-8b9e-a53d952feb7f"
      },
      "source": [
        "model_l2_dist = get_model(with_batch_normalization = False, distance_func='l2')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ed3fdf763adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_l2_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_batch_normalization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awJOmOilH2Ub"
      },
      "source": [
        "##Model Training with l2 distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNnWHvcrH5pj"
      },
      "source": [
        "# run fit with gpu\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# add early stopping callback\n",
        "earlistopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history = model_l2_dist.fit(x= X_train, y= np.asarray(y_train).astype(np.float32), batch_size=32, epochs= 200, validation_data = (X_val, np.asarray(y_val)),\n",
        "                      callbacks=[earlistopping_callback] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNepPpG7IYk1"
      },
      "source": [
        "##Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWGid2Y6IegF"
      },
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwg608hyIaPj"
      },
      "source": [
        "# Test data\n",
        "test_meta_data = load_txt_file_data(test_file_path)\n",
        "test_data = get_pairs_pics_label(test_meta_data)\n",
        "X1_test, X2_test, y_test = get_x_y(test_data)\n",
        "X_test = [np.asarray(X1_test), np.asarray(X2_test)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW5LNpfeIlXZ"
      },
      "source": [
        "###Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVm5QudImwv"
      },
      "source": [
        "# Test accuracy\n",
        "with tf.device('/device:GPU:0'):\n",
        "  pred = model_l2_dist.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZtqTMm3OPWD"
      },
      "source": [
        "### Plot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdmmV-4zIvKV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#  Train and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Train and validation loss \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71BpbxEDLFs1"
      },
      "source": [
        "###Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Tj2zJILP54"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymVprLKSe781"
      },
      "source": [
        "#ImageNet Based Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKnQ1HCJe7mr"
      },
      "source": [
        "def get_pairs_pics_label_3_channels(data_list):\n",
        "  \"\"\"\n",
        "  gets a data list of tuples and returns two pictures in gray scale and\n",
        "  their label - 0 for different and 1 for same\n",
        "  \"\"\"\n",
        "  \n",
        "  res_list = []\n",
        "\n",
        "  for pair in data_list:\n",
        "    first_name, first_pic_num, second_name, second_pic_num, label = pair\n",
        "    \n",
        "    first_img_path = get_image_path(first_name, first_pic_num)\n",
        "    second_img_path = get_image_path(second_name, second_pic_num)\n",
        "\n",
        "    img_size=(105,105)\n",
        "    first_img = load_img(path = first_img_path, color_mode = 'grayscale', target_size=img_size)\n",
        "    first_img = img_to_array(first_img)\n",
        "    first_img = np.repeat(first_img, 3, 2)\n",
        "    second_img = load_img(path = second_img_path, color_mode = 'grayscale', target_size=img_size)\n",
        "    second_img = img_to_array(second_img)\n",
        "    second_img = np.repeat(second_img, 3, 2)\n",
        "\n",
        "    pair_data = (first_img, second_img, label)\n",
        "    res_list.append(pair_data)\n",
        "  \n",
        "  return res_list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_O4GqcmdKfV"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "def dist(vect):\n",
        "    x, y = vect\n",
        "    return abs(x-y)\n",
        "\n",
        "def get_imagenet_based_model():\n",
        "  # Freeze first 10 layers\n",
        "  VGG = VGG16(include_top=False, input_shape=(105,105,3))\n",
        "  for layer in VGG.layers[:19]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  input_shape = (105, 105, 3)\n",
        "  left_input = Input(input_shape)\n",
        "  right_input = Input(input_shape)\n",
        "\n",
        "  convnet = Sequential()\n",
        "  convnet.add(VGG)\n",
        "  convnet.add(Flatten())\n",
        "  convnet.add(Dense(512, activation='relu', kernel_regularizer=l2(0.05)))\n",
        "\n",
        "  encoded_l = convnet(left_input)\n",
        "  encoded_r = convnet(right_input)\n",
        "\n",
        "  merge_layer = Lambda(dist)([encoded_l,encoded_r])\n",
        "  prediction = Dense(1,activation='sigmoid')(merge_layer)\n",
        "  model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = Adam(), metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_U0p36nJl9h"
      },
      "source": [
        "##Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KHZ5p8fgcAR"
      },
      "source": [
        "train_meta_data, val_meta_data = load_txt_file_data(train_file_path, create_validation = True)\n",
        "\n",
        "# process train data\n",
        "train_data = get_pairs_pics_label_3_channels(train_meta_data)\n",
        "X1_train, X2_train, y_train = get_x_y(train_data)\n",
        "X_train = [np.asarray(X1_train), np.asarray(X2_train)]\n",
        "\n",
        "# process validation data\n",
        "val_data = get_pairs_pics_label_3_channels(val_meta_data)\n",
        "X1_val, X2_val, y_val = get_x_y(val_data)\n",
        "X_val = [np.asarray(X1_val), np.asarray(X2_val)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uguCJHMJoQL"
      },
      "source": [
        "##Get Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3AEWJ32eRfd"
      },
      "source": [
        "model_imagenet = get_imagenet_based_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YhmERnrJ0na"
      },
      "source": [
        "##ImageNet Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUW-qEIaJ6vy"
      },
      "source": [
        "# run fit with gpu\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# add early stopping callback\n",
        "earlistopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history = model_imagenet.fit(x= X_train, y= np.asarray(y_train).astype(np.float32), batch_size=32, epochs= 200, validation_data = (X_val, np.asarray(y_val)),\n",
        "                      callbacks=[earlistopping_callback] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5CO99VjEnuz"
      },
      "source": [
        "##Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2jDlYKNKJsZ"
      },
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acops51VEohB"
      },
      "source": [
        "# Test data\n",
        "test_meta_data = load_txt_file_data(test_file_path)\n",
        "test_data = get_pairs_pics_label_3_channels(test_meta_data)\n",
        "X1_test, X2_test, y_test = get_x_y(test_data)\n",
        "X_test = [np.asarray(X1_test), np.asarray(X2_test)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q6wbrG7KINy"
      },
      "source": [
        "###Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfgo6ZTsEuWH"
      },
      "source": [
        "# Test accuracy\n",
        "with tf.device('/device:GPU:0'):\n",
        "  pred = model_imagenet.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMKMzTIlKS3i"
      },
      "source": [
        "###Plot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMPlDAYRMkTW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#  Train and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Train and validation loss \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2ObYG5uKl4y"
      },
      "source": [
        "###Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tngoufVrK-Gp"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HjuGoShOT-F"
      },
      "source": [
        "#Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q84MXzwdwV9B"
      },
      "source": [
        "# Test data\n",
        "test_meta_data = load_txt_file_data(test_file_path)\n",
        "test_data = get_pairs_pics_label(test_meta_data)\n",
        "X1_test, X2_test, y_test = get_x_y(test_data)\n",
        "X_test = [np.asarray(X1_test), np.asarray(X2_test)]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bffTIYKy0cP"
      },
      "source": [
        "# Test accuracy\n",
        "with tf.device('/device:GPU:0'):\n",
        "  pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8yxHagCzXRM"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "# print(pred.shape)\n",
        "\n",
        "# print(pred)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APcgCsZUau1c"
      },
      "source": [
        "# Test accuracy\n",
        "with tf.device('/device:GPU:0'):\n",
        "  pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apYN82gIawDi"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shgRBn9a0P5b"
      },
      "source": [
        "# Extra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMe7s5Ys_jHp",
        "outputId": "e8b4f972-ea00-4cce-a0d5-cdbfef11b7fb"
      },
      "source": [
        "test_file_name = \"pairsDevTrain.txt\"\n",
        "train_file = open(train_file_name)\n",
        "train_meta_data = train_file.read()\n",
        "train_meta_data_list = train_meta_data.split('\\n')\n",
        "print(train_meta_data_list[1100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zinedine_Zidane\t2\t4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrpY1R4Uf0Rr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmdsmUxyDcmN",
        "outputId": "a98ac5fb-3197-4281-f7f7-e5283f82e70c"
      },
      "source": [
        "sample = train_meta_data_list[0].split('\\t')\n",
        "name = sample[0]\n",
        "first_image_ext = sample[1]\n",
        "second_image_ext = sample[2]\n",
        "sample_path = os.path.join(data_path, name)\n",
        "for file_name in os.listdir(sample_path):\n",
        "  first_image_name = file_name if file_name.endswith(first_image_ext + \".jpg\") else first_image_name\n",
        "  second_image_name = file_name if file_name.endswith(second_image_ext + \".jpg\") else second_image_name\n",
        "\n",
        "first_image_path = os.path.join(sample_path, first_image_path)\n",
        "second_image_path = os.path.join(sample_path, second_image_path)\n",
        "\n",
        "print(second_image_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aaron_Peirsol_0002.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0BkITfpPaiy",
        "outputId": "8ab0306c-3dd9-49ef-ff5b-345f2043fa51"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 105, 105, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4096)         38947648    input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           sequential_2[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            2           lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 38,947,650\n",
            "Trainable params: 38,947,650\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGXdR30qP8CL",
        "outputId": "ec75e723-b6bd-4203-ee9f-bbcb8d943e88"
      },
      "source": [
        "model.train_on_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function fetch_lfw_pairs at 0x7f1049a75a70>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wggTLvq8oCZ",
        "outputId": "3d2a66c7-1f1d-4323-cbc8-12106e86bfa2"
      },
      "source": [
        "# Get unzipped data\n",
        "\n",
        "import os\n",
        "\n",
        "# d = open(\"data/lfw2/lfw2\", )\n",
        "data_path = \"data/lfw2/lfw2\"\n",
        "os.listdir(data_path)\n",
        "\n",
        "jpath = os.path.join(data_path, \"James_Mathis\")\n",
        "os.listdir(jpath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['James_Mathis_0001.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B18rQRkhEzZf"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Values binarization \n",
        "pred = np.where(pred > 0.5, 1, 0)\n",
        "# print(pred.shape)\n",
        "\n",
        "# print(pred)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}